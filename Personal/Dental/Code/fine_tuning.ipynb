{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# KoELECTRA Tokenizer 및 Model 로드\n",
    "model_name = \"beomi/koelectra-base-v3-discriminator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=5\n",
    ")  # 치과 관련 카테고리 개수만큼 설정\n",
    "\n",
    "# 치과 관련 데이터셋 준비\n",
    "# 여기에 치과 관련 텍스트와 라벨이 있어야 합니다.\n",
    "# 예시 데이터 (질문과 라벨)\n",
    "texts = [\n",
    "    \"어금니가 너무 아파요, 신경치료가 필요할까요?\",\n",
    "    \"잇몸에서 피가 나요, 잇몸 치료가 필요해요.\",\n",
    "    \"앞니를 때웠는데, 보철물 문제가 있는 것 같아요.\",\n",
    "    \"치아가 시려요, 충치 때문인가요?\",\n",
    "    \"교정 치료가 필요한가요? 치아가 삐뚤어요.\",\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    0,\n",
    "    3,\n",
    "]  # 각 라벨에 해당하는 진료 항목 (0: 신경치료, 1: 잇몸 치료, 2: 보철물 문제, 3: 교정 치료)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "\n",
    "# Pytorch Dataset 클래스로 변환\n",
    "class DentalDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = DentalDataset(train_encodings, train_labels)\n",
    "val_dataset = DentalDataset(val_encodings, val_labels)\n",
    "\n",
    "# TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # 학습 결과 저장 경로\n",
    "    num_train_epochs=3,  # 학습 에포크 수\n",
    "    per_device_train_batch_size=8,  # 배치 크기\n",
    "    per_device_eval_batch_size=8,  # 평가 시 배치 크기\n",
    "    warmup_steps=500,  # 학습 시작 전에 learning rate가 증가하는 단계 수\n",
    "    weight_decay=0.01,  # 가중치 감소 (regularization)\n",
    "    logging_dir=\"./logs\",  # 로그 저장 경로\n",
    "    logging_steps=10,  # 로그 남길 스텝 간격\n",
    "    evaluation_strategy=\"steps\",  # 평가 전략 (에포크별 또는 스텝별 평가)\n",
    "    eval_steps=50,  # 평가할 스텝 간격\n",
    "    save_steps=100,  # 모델을 저장할 스텝 간격\n",
    "    load_best_model_at_end=True,  # 최고의 성능을 보인 모델을 마지막에 로드\n",
    ")\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "# 모델 평가\n",
    "trainer.evaluate()\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model(\"./fine_tuned_koelectra_dental\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_koelectra_dental\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
