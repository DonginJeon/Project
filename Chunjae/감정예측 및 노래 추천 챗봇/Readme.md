# 감정 예측 및 노래 추천 챗봇 서비스 보고서

### 프로젝트 개요

이 프로젝트는 AI hub의 ‘감성 대화 말뭉치 데이터’를 기반으로, KoELECTRA 모델을 학습시켜 감정 예측 및 음악 추천 챗봇 서비스를 개발한 것입니다. 사용자의 대화 데이터를 바탕으로 감정 상태를 분석하고, 사용자 감정에 맞는 음악을 추천함으로써 감정적 위로와 도움을 주는 것을 목표로 하였습니다.

---

### 프로젝트 목표

이 챗봇 서비스는 사용자의 감정 상태를 예측하여 그에 맞는 노래를 추천하는 기능을 제공합니다. 구체적으로, 대화가 반복될수록 감정 예측의 정확도를 높이며, 감정에 따른 음악 추천 기능을 통해 사용자에게 감정적 위로와 공감을 제공하고자 합니다.

대상 사용자로는 다음과 같은 두 가지 그룹을 설정했습니다:

- 음악에 대한 구체적 선호가 없으나 감정에 맞는 음악을 듣고 싶은 사람
- 자신의 감정이 불안정하여 대화와 음악을 통해 위로받고자 하는 사람

---

### 프로젝트 결과

- **모델 학습 및 감정 예측**  
  KoELECTRA의 `koelectra-base-v3-discriminator` 모델을 사용하여 감정을 예측하는 모델을 구축했습니다. AI Hub의 감성 대화 데이터를 바탕으로 모델을 훈련하고, 사용자가 입력하는 대화를 분석하여 감정을 예측할 수 있도록 했습니다. 대화 데이터를 훈련(80%)과 테스트(20%)로 분할하여 학습시키고, 감정 라벨은 총 6가지로 분류하였습니다.

  훈련 데이터의 규모가 크기 때문에 학습 시간 절약을 위해 랜덤으로 선택한 20%의 데이터만 사용했습니다. ElectraTokenizer를 통해 텍스트를 토큰화하고, ElectraForSequenceClassification을 사용해 감정 상태를 학습하였습니다.

- **웹 프레임워크 구축**  
  웹 프레임워크는 Flask를 사용하여 구축하였으며, 사용자가 3번의 대화를 거친 후 감정을 예측해 노래를 추천하는 챗봇 구조를 설계하였습니다. 챗봇은 사용자가 자신의 감정을 이야기하도록 유도하며, 감정을 예측한 후 미리 라벨링된 노래와 매칭하여 감정에 맞는 음악을 추천합니다. 감정 상태는 학습 때와 동일한 6가지로 나누었고, 각 감정별로 2곡씩 노래를 변수에 저장했습니다.

- **노래 추천 기능**  
  감정 예측 결과에 따라 적합한 노래를 추천하고, 유튜브 링크로 연결하여 사용자가 추천된 음악을 쉽게 들을 수 있도록 구현했습니다. 이는 감정 라벨에 따른 음악의 적합성을 높이고, 사용자가 바로 음악을 감상함으로써 보다 빠른 감정적 도움을 받을 수 있도록 돕는 기능입니다.

---

### 어려움

1. **긍정 감정 분류의 어려움**  
   감정 라벨링에서 긍정 감정이 하나밖에 없기 때문에 긍정의 문장이 '분노'로 잘못 분류되는 문제가 발생했습니다. 이는 Koelectra 모델이 긍정과 부정 감정을 효과적으로 구분하지 못하는 한계를 드러내며, 챗봇 사용자 경험을 저하시키는 요인이 되었습니다.

2. **음악 데이터베이스 확장성 부족**  
   현재 시스템에서는 노래가 변수에 저장되어 있어 한정된 곡만을 추천할 수 있었습니다. 이로 인해 다양한 감정 상태에 맞춘 방대한 음악 라이브러리의 활용에 한계가 있었습니다.

---

### 해결 방안

- **다중 모델 적용**  
  Koelectra 모델의 한계를 보완하기 위해 `nlptown/bert-base-multilingual-uncased-sentiment` 모델을 추가했습니다. 사용자가 입력한 문장을 KoELECTRA 모델에 전달하기 전에, 우선 문장의 긍정/부정을 구분하여 긍정일 경우 감정을 ‘기쁨’으로 설정하고, 긍정이 아닌 경우 Koelectra 모델을 통해 감정을 다시 예측하도록 설계했습니다. 이를 통해 긍정 감정의 분류 정확도를 향상시키는 성과를 거두었습니다.

- **노래 링크 추가**  
  추천된 노래와 함께 유튜브 링크를 제공하여 사용자가 손쉽게 음악을 감상할 수 있도록 했습니다. 이를 통해 감정 상태에 맞는 노래를 더 직관적으로 추천하며, 사용자의 편의성을 높였습니다.

---

### 한계 및 향후 개선 방안

- **모델의 감정 분류 성능**  
  KoELECTRA 모델을 보완하기 위해 추가 학습이 필요합니다. 10000개 이상의 데이터 중 20%만 사용했기 때문에 나머지 80%의 데이터로 추가 학습을 진행하면 성능이 향상될 것으로 예상됩니다. 다만, 훈련에 약 11시간이 소요되는 점을 감안할 때, 학습 환경의 최적화가 필요합니다.

- **음악 데이터베이스 확장**  
  현재는 감정에 따라 추천할 수 있는 노래가 제한적이므로, API를 사용하여 방대한 음악 라이브러리를 활용할 수 있는 방안을 고려하고 있습니다. 또한, 음악 DB에 감정별 라벨을 미리 지정하여 추천 곡의 다양성을 확보하고자 합니다.

- **대화 유도 방식 개선**  
  현재 챗봇이 사용자에게 같은 말로 반복해서 3번의 감정을 묻는 방식인데, 대화 유도 문구를 추가해 보다 자연스러운 상호작용이 가능하도록 개선할 계획입니다.

---

### 배운 점과 성장

- **다중 모델의 효과적인 활용**  
  긍정과 부정 감정을 구분하기 위해 두 개의 모델을 활용함으로써, LLM 모델의 한계를 보완하고 성능을 개선할 수 있는 방법을 배우게 되었습니다. 이러한 다중 모델 사용은 향후 유사 프로젝트에서 유용할 것으로 기대됩니다.

- **API를 통한 확장성 확보의 중요성**  
  API를 활용하여 감정에 맞는 노래를 방대한 라이브러리에서 자동으로 추천받을 수 있는 방안에 대해 고민하게 되었습니다. 이를 통해 서비스 확장성과 유연성을 확보할 수 있음을 깨달았습니다.

- **사용자 경험 개선을 위한 상호작용 설계**  
  챗봇의 대화 유도 방식을 개선하는 과정을 통해 사용자 경험이 서비스의 중요한 요소임을 배웠고, 사용자와의 자연스러운 상호작용이 서비스 완성도를 높일 수 있다는 점을 학습했습니다.

---

이상으로 감정 예측 및 노래 추천 챗봇 프로젝트 보고서를 마칩니다.
